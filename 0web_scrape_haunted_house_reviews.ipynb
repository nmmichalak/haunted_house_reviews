{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test webscraping haunted house reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haunted World website URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "homepage_url = \"https://www.hauntworld.com/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "homepage_response = requests.get(homepage_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "homepage_soup = BeautifulSoup(homepage_response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alabama-haunted-houses',\n",
       " 'alaska-haunted-houses',\n",
       " 'arizona-haunted-houses',\n",
       " 'arkansas-haunted-houses',\n",
       " 'california-haunted-houses',\n",
       " 'colorado-haunted-houses',\n",
       " 'connecticut-haunted-houses',\n",
       " 'delaware-haunted-houses',\n",
       " 'district-of-columbia-haunted-houses',\n",
       " 'florida-haunted-houses',\n",
       " 'georgia-haunted-houses',\n",
       " 'hawaii-haunted-houses',\n",
       " 'idaho-haunted-houses',\n",
       " 'illinois-haunted-houses',\n",
       " 'indiana-haunted-houses',\n",
       " 'iowa-haunted-houses',\n",
       " 'kansas-haunted-houses',\n",
       " 'kentucky-haunted-houses',\n",
       " 'louisiana-haunted-houses',\n",
       " 'maine-haunted-houses',\n",
       " 'maryland-haunted-houses',\n",
       " 'massachusetts-haunted-houses',\n",
       " 'michigan-haunted-houses',\n",
       " 'minnesota-haunted-houses',\n",
       " 'mississippi-haunted-houses',\n",
       " 'missouri-haunted-houses',\n",
       " 'montana-haunted-houses',\n",
       " 'nebraska-haunted-houses',\n",
       " 'nevada-haunted-houses',\n",
       " 'new-hampshire-haunted-houses',\n",
       " 'new-jersey-haunted-houses',\n",
       " 'new-mexico-haunted-houses',\n",
       " 'new-york-haunted-houses',\n",
       " 'north-carolina-haunted-houses',\n",
       " 'north-dakota-haunted-houses',\n",
       " 'ohio-haunted-houses',\n",
       " 'oklahoma-haunted-houses',\n",
       " 'oregon-haunted-houses',\n",
       " 'pennsylvania-haunted-houses',\n",
       " 'rhode-island-haunted-houses',\n",
       " 'south-carolina-haunted-houses',\n",
       " 'south-dakota-haunted-houses',\n",
       " 'tennessee-haunted-houses',\n",
       " 'texas-haunted-houses',\n",
       " 'utah-haunted-houses',\n",
       " 'vermont-haunted-houses',\n",
       " 'virginia-haunted-houses',\n",
       " 'washington-haunted-houses',\n",
       " 'west-virginia-haunted-houses',\n",
       " 'wisconsin-haunted-houses',\n",
       " 'wyoming-haunted-houses',\n",
       " 'newfoundland-haunted-houses',\n",
       " 'nova-scotia-haunted-houses',\n",
       " 'new-brunswick-haunted-houses',\n",
       " 'quebec-haunted-houses',\n",
       " 'ontario-haunted-houses',\n",
       " 'manitoba-haunted-houses',\n",
       " 'saskatchewan-haunted-houses',\n",
       " 'alberta-haunted-houses',\n",
       " 'british-columbia-haunted-houses',\n",
       " 'northwest-territories-haunted-houses',\n",
       " 'yukon-haunted-houses',\n",
       " 'international-haunted-houses']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_href = []\n",
    "for a in homepage_soup.find(\"div\", class_ = \"col-md-12 col-sm-12 col-xs-12 x-min-padding text-center\").find_all(\"a\"):\n",
    "    state_href.append(a[\"href\"])\n",
    "\n",
    "# See them\n",
    "state_href"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haunted World State URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.hauntworld.com/alabama-haunted-houses',\n",
       " 'https://www.hauntworld.com/alaska-haunted-houses',\n",
       " 'https://www.hauntworld.com/arizona-haunted-houses',\n",
       " 'https://www.hauntworld.com/arkansas-haunted-houses',\n",
       " 'https://www.hauntworld.com/california-haunted-houses',\n",
       " 'https://www.hauntworld.com/colorado-haunted-houses',\n",
       " 'https://www.hauntworld.com/connecticut-haunted-houses',\n",
       " 'https://www.hauntworld.com/delaware-haunted-houses',\n",
       " 'https://www.hauntworld.com/district-of-columbia-haunted-houses',\n",
       " 'https://www.hauntworld.com/florida-haunted-houses',\n",
       " 'https://www.hauntworld.com/georgia-haunted-houses',\n",
       " 'https://www.hauntworld.com/hawaii-haunted-houses',\n",
       " 'https://www.hauntworld.com/idaho-haunted-houses',\n",
       " 'https://www.hauntworld.com/illinois-haunted-houses',\n",
       " 'https://www.hauntworld.com/indiana-haunted-houses',\n",
       " 'https://www.hauntworld.com/iowa-haunted-houses',\n",
       " 'https://www.hauntworld.com/kansas-haunted-houses',\n",
       " 'https://www.hauntworld.com/kentucky-haunted-houses',\n",
       " 'https://www.hauntworld.com/louisiana-haunted-houses',\n",
       " 'https://www.hauntworld.com/maine-haunted-houses',\n",
       " 'https://www.hauntworld.com/maryland-haunted-houses',\n",
       " 'https://www.hauntworld.com/massachusetts-haunted-houses',\n",
       " 'https://www.hauntworld.com/michigan-haunted-houses',\n",
       " 'https://www.hauntworld.com/minnesota-haunted-houses',\n",
       " 'https://www.hauntworld.com/mississippi-haunted-houses',\n",
       " 'https://www.hauntworld.com/missouri-haunted-houses',\n",
       " 'https://www.hauntworld.com/montana-haunted-houses',\n",
       " 'https://www.hauntworld.com/nebraska-haunted-houses',\n",
       " 'https://www.hauntworld.com/nevada-haunted-houses',\n",
       " 'https://www.hauntworld.com/new-hampshire-haunted-houses',\n",
       " 'https://www.hauntworld.com/new-jersey-haunted-houses',\n",
       " 'https://www.hauntworld.com/new-mexico-haunted-houses',\n",
       " 'https://www.hauntworld.com/new-york-haunted-houses',\n",
       " 'https://www.hauntworld.com/north-carolina-haunted-houses',\n",
       " 'https://www.hauntworld.com/north-dakota-haunted-houses',\n",
       " 'https://www.hauntworld.com/ohio-haunted-houses',\n",
       " 'https://www.hauntworld.com/oklahoma-haunted-houses',\n",
       " 'https://www.hauntworld.com/oregon-haunted-houses',\n",
       " 'https://www.hauntworld.com/pennsylvania-haunted-houses',\n",
       " 'https://www.hauntworld.com/rhode-island-haunted-houses',\n",
       " 'https://www.hauntworld.com/south-carolina-haunted-houses',\n",
       " 'https://www.hauntworld.com/south-dakota-haunted-houses',\n",
       " 'https://www.hauntworld.com/tennessee-haunted-houses',\n",
       " 'https://www.hauntworld.com/texas-haunted-houses',\n",
       " 'https://www.hauntworld.com/utah-haunted-houses',\n",
       " 'https://www.hauntworld.com/vermont-haunted-houses',\n",
       " 'https://www.hauntworld.com/virginia-haunted-houses',\n",
       " 'https://www.hauntworld.com/washington-haunted-houses',\n",
       " 'https://www.hauntworld.com/west-virginia-haunted-houses',\n",
       " 'https://www.hauntworld.com/wisconsin-haunted-houses',\n",
       " 'https://www.hauntworld.com/wyoming-haunted-houses',\n",
       " 'https://www.hauntworld.com/newfoundland-haunted-houses',\n",
       " 'https://www.hauntworld.com/nova-scotia-haunted-houses',\n",
       " 'https://www.hauntworld.com/new-brunswick-haunted-houses',\n",
       " 'https://www.hauntworld.com/quebec-haunted-houses',\n",
       " 'https://www.hauntworld.com/ontario-haunted-houses',\n",
       " 'https://www.hauntworld.com/manitoba-haunted-houses',\n",
       " 'https://www.hauntworld.com/saskatchewan-haunted-houses',\n",
       " 'https://www.hauntworld.com/alberta-haunted-houses',\n",
       " 'https://www.hauntworld.com/british-columbia-haunted-houses',\n",
       " 'https://www.hauntworld.com/northwest-territories-haunted-houses',\n",
       " 'https://www.hauntworld.com/yukon-haunted-houses',\n",
       " 'https://www.hauntworld.com/international-haunted-houses']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_page_urls = [homepage_url + href for href in state_href]\n",
    "\n",
    "# See them\n",
    "state_page_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State page responses and soups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made soup 0. Sleeping for [3] seconds...\n",
      "Made soup 1. Sleeping for [4] seconds...\n",
      "Made soup 2. Sleeping for [4] seconds...\n",
      "Made soup 3. Sleeping for [3] seconds...\n",
      "Made soup 4. Sleeping for [4] seconds...\n",
      "Made soup 5. Sleeping for [1] seconds...\n",
      "Made soup 6. Sleeping for [1] seconds...\n",
      "Made soup 7. Sleeping for [2] seconds...\n",
      "Made soup 8. Sleeping for [3] seconds...\n",
      "Made soup 9. Sleeping for [3] seconds...\n",
      "Made soup 10. Sleeping for [1] seconds...\n",
      "Made soup 11. Sleeping for [2] seconds...\n",
      "Made soup 12. Sleeping for [1] seconds...\n",
      "Made soup 13. Sleeping for [4] seconds...\n",
      "Made soup 14. Sleeping for [3] seconds...\n",
      "Made soup 15. Sleeping for [2] seconds...\n",
      "Made soup 16. Sleeping for [2] seconds...\n",
      "Made soup 17. Sleeping for [3] seconds...\n",
      "Made soup 18. Sleeping for [3] seconds...\n",
      "Made soup 19. Sleeping for [1] seconds...\n",
      "Made soup 20. Sleeping for [4] seconds...\n",
      "Made soup 21. Sleeping for [3] seconds...\n",
      "Made soup 22. Sleeping for [4] seconds...\n",
      "Made soup 23. Sleeping for [1] seconds...\n",
      "Made soup 24. Sleeping for [3] seconds...\n",
      "Made soup 25. Sleeping for [1] seconds...\n",
      "Made soup 26. Sleeping for [2] seconds...\n",
      "Made soup 27. Sleeping for [1] seconds...\n",
      "Made soup 28. Sleeping for [4] seconds...\n",
      "Made soup 29. Sleeping for [2] seconds...\n",
      "Made soup 30. Sleeping for [4] seconds...\n",
      "Made soup 31. Sleeping for [4] seconds...\n",
      "Made soup 32. Sleeping for [4] seconds...\n",
      "Made soup 33. Sleeping for [1] seconds...\n",
      "Made soup 34. Sleeping for [3] seconds...\n",
      "Made soup 35. Sleeping for [3] seconds...\n",
      "Made soup 36. Sleeping for [2] seconds...\n",
      "Made soup 37. Sleeping for [2] seconds...\n",
      "Made soup 38. Sleeping for [2] seconds...\n",
      "Made soup 39. Sleeping for [1] seconds...\n",
      "Made soup 40. Sleeping for [3] seconds...\n",
      "Made soup 41. Sleeping for [4] seconds...\n",
      "Made soup 42. Sleeping for [4] seconds...\n",
      "Made soup 43. Sleeping for [2] seconds...\n",
      "Made soup 44. Sleeping for [2] seconds...\n",
      "Made soup 45. Sleeping for [1] seconds...\n",
      "Made soup 46. Sleeping for [1] seconds...\n",
      "Made soup 47. Sleeping for [1] seconds...\n",
      "Made soup 48. Sleeping for [1] seconds...\n",
      "Made soup 49. Sleeping for [2] seconds...\n",
      "Made soup 50. Sleeping for [3] seconds...\n",
      "Made soup 51. Sleeping for [3] seconds...\n",
      "Made soup 52. Sleeping for [4] seconds...\n",
      "Made soup 53. Sleeping for [3] seconds...\n",
      "Made soup 54. Sleeping for [2] seconds...\n",
      "Made soup 55. Sleeping for [3] seconds...\n",
      "Made soup 56. Sleeping for [4] seconds...\n",
      "Made soup 57. Sleeping for [3] seconds...\n",
      "Made soup 58. Sleeping for [2] seconds...\n",
      "Made soup 59. Sleeping for [3] seconds...\n",
      "Made soup 60. Sleeping for [1] seconds...\n",
      "Made soup 61. Sleeping for [1] seconds...\n",
      "Made soup 62. Sleeping for [3] seconds...\n"
     ]
    }
   ],
   "source": [
    "# containers for responses and soups\n",
    "state_page_responses = []\n",
    "state_page_soups = []\n",
    "\n",
    "# loop through urls to make soup\n",
    "for i, url_i in enumerate(state_page_urls):\n",
    "    # get url response\n",
    "    response_i = requests.get(url_i)\n",
    "    \n",
    "    # make soup\n",
    "    soup_i = BeautifulSoup(response_i.text, \"html.parser\")\n",
    "    \n",
    "    # add response and soup to their containers\n",
    "    state_page_responses.append(response_i)\n",
    "    state_page_soups.append(soup_i)\n",
    "    \n",
    "    # sleep for 1-5 seconds\n",
    "    sleep_time_i = np.random.randint(low = 1, high = 5, size = 1)\n",
    "    time.sleep(sleep_time_i)\n",
    "    \n",
    "    # Print loop message\n",
    "    print(\"Made soup {}. Sleeping for {} seconds...\".format(i, sleep_time_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haunt page href and titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hollis Haunted Chicken House in Heflin, Alabama (https://www.hauntworld.com//haunted-house-in-heflin-Alabama-hollis-haunted-chicken)\n",
      "NETHERWORLD Haunted House in Stone Mountain, Georgia (https://www.hauntworld.com//haunted-house-in-norcross-Georgia-netherworld-haunted-house)\n",
      "None\n",
      "Mount Mayhem Haunted House in PHOENIX, Arizona (https://www.hauntworld.com//haunted-house-in-phoenix-arizona-mount-mayhem-haunted-house)\n",
      "The Haunted Hotel of Arkansas in Little Rock, Arkansas (https://www.hauntworld.com//haunted-house-in-little-rock-Arkansas-the-haunted-hotel)\n",
      "The Darkness in Saint Louis, Missouri (https://www.hauntworld.com//haunted-house-in-saint-louis-Missouri-the-darkness)\n",
      "Creepyworld Screampark in Saint Louis/Fenton, Missouri (https://www.hauntworld.com//haunted-house-in-saint-louis-fenton-missouri-creepyworld-screampark)\n",
      "Lemp Haunted House in St. Louis, Missouri (https://www.hauntworld.com//haunted-house-in-st-louis-Missouri-lemp-brewery-haunted)\n",
      "Winchester Mystery House - Unhinged in San Jose, California (https://www.hauntworld.com//winchestermysteryhouse)\n"
     ]
    }
   ],
   "source": [
    "# containers for haunt href and titles\n",
    "haunt_href = []\n",
    "haunt_titles = []\n",
    "\n",
    "for soup_i in state_page_soups[0:5]:\n",
    "    try:\n",
    "        for div in soup_i.find(\"div\", {\"class\": \"row mt-4\"}).find_all(\"div\", {\"class\": \"panel-heading text-bold responsive-text-center\"}):\n",
    "            # href for making url to haunt specific page\n",
    "            href_i = (div\n",
    "                      .find(\"div\", {\"class\": \"col-md-8 p-0\"})\n",
    "                      .find(\"a\")[\"href\"])\n",
    "\n",
    "            # haunt title\n",
    "            haunt_title_i = (div\n",
    "                             .find(\"div\", {\"class\": \"col-md-8 p-0\"})\n",
    "                             .find(\"h4\", {\"class\": \"p-0 m-0\"})\n",
    "                             .find(\"u\")\n",
    "                             .get_text())\n",
    "\n",
    "            # append href and title to their containers\n",
    "            haunt_href.append(href_i)\n",
    "            haunt_titles.append(haunt_title_i)\n",
    "\n",
    "            # sleep for 1-5 seconds\n",
    "            sleep_time_i = np.random.randint(low = 1, high = 5, size = 1)\n",
    "            time.sleep(sleep_time_i)\n",
    "            \n",
    "            # print titles\n",
    "            print(haunt_title_i + \" (\" + homepage_url + href_i + \")\")\n",
    "    except:\n",
    "        # append href and title to their containers\n",
    "        haunt_href.append(\"None\")\n",
    "        haunt_titles.append(\"None\")\n",
    "        \n",
    "        # print titles\n",
    "        print(\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haunt review pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.hauntworld.com/haunted-house-in-heflin-Alabama-hollis-haunted-chicken',\n",
       " 'https://www.hauntworld.com/haunted-house-in-norcross-Georgia-netherworld-haunted-house',\n",
       " 'https://www.hauntworld.com/None',\n",
       " 'https://www.hauntworld.com/haunted-house-in-phoenix-arizona-mount-mayhem-haunted-house',\n",
       " 'https://www.hauntworld.com/haunted-house-in-little-rock-Arkansas-the-haunted-hotel',\n",
       " 'https://www.hauntworld.com/haunted-house-in-saint-louis-Missouri-the-darkness',\n",
       " 'https://www.hauntworld.com/haunted-house-in-saint-louis-fenton-missouri-creepyworld-screampark',\n",
       " 'https://www.hauntworld.com/haunted-house-in-st-louis-Missouri-lemp-brewery-haunted',\n",
       " 'https://www.hauntworld.com/winchestermysteryhouse']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haunt_page_urls = [homepage_url + href.strip(\"/\") for href in haunt_href]\n",
    "\n",
    "# See them\n",
    "haunt_page_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haunt addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address: 7522 AL-1, Heflin, Alabama 36264, US.\n",
      "Address: 2076 West Park Place Blvd., Stone Mountain, Georgia 30087, USA.\n",
      "Address: 1740 E Purdue Ave, PHOENIX, Arizona 85020, USA.\n",
      "Address: 4601 So University, Little Rock, Arkansas 72204, USA.\n",
      "Address: 1525 South 8th Street, Saint Louis, Missouri 63104, USA.\n",
      "Address: 1400 S Old Highway 141, Saint Louis/Fenton, Missouri 63026, USA.\n",
      "Address: 3500 Lemp Avenue , St. Louis, Missouri 63118, united states.\n",
      "Address: 525 S. Winchester Blvd, San Jose, California 95128, United States.\n"
     ]
    }
   ],
   "source": [
    "# containers for haunt addresses\n",
    "haunt_addresses = []\n",
    "\n",
    "for soup_i in state_page_soups[0:5]:\n",
    "    try:\n",
    "        for child in soup_i.select(\"div.font-14:nth-child(1)\"):\n",
    "            # haunt address\n",
    "            haunt_addresse_i = child.get_text()\n",
    "            \n",
    "            # add to address container\n",
    "            haunt_addresses.append(haunt_addresse_i)\n",
    "            \n",
    "            # print address\n",
    "            print(haunt_addresse_i)\n",
    "    except:\n",
    "        haunt_addresses.append(\"None\")\n",
    "        print(\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haunt review page attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Web reviews\n",
      "1 Youtube Videos\n",
      "9 Photos\n",
      "62679 Profile Views\n",
      "12 Web reviews\n",
      "28 Youtube Videos\n",
      "37 Photos\n",
      "226086 Profile Views\n",
      "5 Web reviews\n",
      "3 Youtube Videos\n",
      "36 Photos\n",
      "26967 Profile Views\n",
      "17 Web reviews\n",
      "0 Youtube Videos\n",
      "0 Photos\n",
      "34772 Profile Views\n",
      "9 Web reviews\n",
      "51 Youtube Videos\n",
      "230 Photos\n",
      "270510 Profile Views\n",
      "4 Web reviews\n",
      "25 Youtube Videos\n",
      "202 Photos\n",
      "236402 Profile Views\n",
      "5 Web reviews\n",
      "22 Youtube Videos\n",
      "80 Photos\n",
      "129797 Profile Views\n",
      "0 Web reviews\n",
      "1 Youtube Videos\n",
      "2 Photos\n",
      "1463 Profile Views\n"
     ]
    }
   ],
   "source": [
    "# containers for haunt web reviews, youtube videos, photos, and profile views\n",
    "haunt_web_reviews = []\n",
    "haunt_youtube_videos = []\n",
    "haunt_photos = []\n",
    "haunt_profile_views = []\n",
    "\n",
    "for soup_i in state_page_soups[0:5]:\n",
    "    try:\n",
    "        for ul in soup_i.find_all(\"ul\", {\"class\": \"list-unstyled skullul\"}):\n",
    "            # get all \"skull attributes\" (containers above name skull attributes)\n",
    "            skull_attributes = [u.get_text() for u in ul.find_all(\"u\")]\n",
    "\n",
    "            # extract attributes in order they appear on page\n",
    "            haunt_web_reviews_i = skull_attributes[0]\n",
    "            haunt_youtube_videos_i = skull_attributes[1]\n",
    "            haunt_photos_i = skull_attributes[2]\n",
    "            haunt_profile_views_i = skull_attributes[3]\n",
    "            \n",
    "            # add to attributes to their containers\n",
    "            haunt_web_reviews.append(haunt_web_reviews_i)\n",
    "            haunt_youtube_videos.append(haunt_youtube_videos_i)\n",
    "            haunt_photos.append(haunt_photos_i)\n",
    "            haunt_profile_views.append(haunt_profile_views_i)\n",
    "            \n",
    "            # print address\n",
    "            print(haunt_web_reviews_i)\n",
    "            print(haunt_youtube_videos_i)\n",
    "            print(haunt_photos_i)\n",
    "            print(haunt_profile_views_i)\n",
    "    except:\n",
    "        haunt_web_reviews.append(\"None\")\n",
    "        haunt_youtube_videos.append(\"None\")\n",
    "        haunt_photos.append(\"None\")\n",
    "        haunt_profile_views.append(\"None\")\n",
    "        print(\"None\\n\" * 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haunt page responses and soups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made soup 0. Sleeping for [4] seconds...\n",
      "Made soup 1. Sleeping for [4] seconds...\n",
      "Made soup 2. Sleeping for [1] seconds...\n",
      "Made soup 3. Sleeping for [2] seconds...\n",
      "Made soup 4. Sleeping for [1] seconds...\n",
      "Made soup 5. Sleeping for [2] seconds...\n",
      "Made soup 6. Sleeping for [1] seconds...\n",
      "Made soup 7. Sleeping for [2] seconds...\n",
      "Made soup 8. Sleeping for [1] seconds...\n"
     ]
    }
   ],
   "source": [
    "# containers for responses and soups\n",
    "haunt_page_responses = []\n",
    "haunt_page_soups = []\n",
    "\n",
    "# loop through urls to make soup\n",
    "for i, url_i in enumerate(haunt_page_urls):\n",
    "    # get url response\n",
    "    response_i = requests.get(url_i)\n",
    "    \n",
    "    # make soup\n",
    "    soup_i = BeautifulSoup(response_i.text, \"html.parser\")\n",
    "    \n",
    "    # add response and soup to their containers\n",
    "    haunt_page_responses.append(response_i)\n",
    "    haunt_page_soups.append(soup_i)\n",
    "    \n",
    "    # sleep for 1-5 seconds\n",
    "    sleep_time_i = np.random.randint(low = 1, high = 5, size = 1)\n",
    "    time.sleep(sleep_time_i)\n",
    "    \n",
    "    # Print loop message\n",
    "    print(\"Made soup {}. Sleeping for {} seconds...\".format(i, sleep_time_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haunt page review titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# container for review titles\n",
    "haunt_review_titles = []\n",
    "\n",
    "for i, soup_i in enumerate(haunt_page_soups[0:5]):\n",
    "    try:\n",
    "        for j, div in enumerate(soup_i.find_all(\"div\", {\"class\": \"text-primary text-semibold col-md-6\"})):\n",
    "            # review title\n",
    "            haunt_review_title_j = div.get_text()\n",
    "            \n",
    "            # add review title to its container\n",
    "            haunt_review_titles.append(haunt_review_title_j)\n",
    "            \n",
    "            # sleep for 1-5 seconds\n",
    "            sleep_time_i = np.random.randint(low = 1, high = 5, size = 1)\n",
    "            time.sleep(sleep_time_i)\n",
    "            \n",
    "            # Print loop message\n",
    "            print(\"Scraped review title {1} from page {2}. Sleeping for {3} seconds...\".format(i, j, sleep_time_i))\n",
    "    except:\n",
    "        haunt_review_titles.append(\"None\")\n",
    "        print(\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haunt page review dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haunt page reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haunt page review skull scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
